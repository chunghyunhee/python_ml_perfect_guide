{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 사이킷런으로 시작하는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 사이킷런 소개와 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__) #사이킷런 버전 확인, 설치확인(anaconda기본)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.첫번째 머신러닝 만들어보기-붓꽃 품종 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "붓꽃 데이터는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 feature을 기반으로 꽃의 품종을 예측하기 위한 것이다. 분류는 대표적인 지도학습 방법의 하나이다. ***지도학습은 학습을 위한 다양한 feature와 분류 결정값인 레이블 데이터로 모델을 학습한 후에 별도의 테스트 데이터 세트에서 미지의 레이블을 예측한다*** 즉 지도학습은 명확한 정답이 주어진 데이터를 먼저 학습시킨 이후에 미지의 정답을 예측하는 방식이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklear.model_selection은 학습데이터와 검증데이터, 예측데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임입니다. ***하이퍼파라미터***란 머신러닝 알고리즘별 최적의 학습을 위해 직접 입력하는 파라미터를 통칭합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris #필요한 데이터 로드\n",
    "from sklearn.tree import DecisionTreeClassifier #사용한 모델 로드\n",
    "from sklearn.model_selection import train_test_split #학습 데이터와 테스트 데이터의 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#붓꽃 데이터 셋을 로딩한다\n",
    "iris=load_iris() #예제 데이터셋을 로딩하는 객체를 선언하는 형태 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\.conda\\\\envs\\\\NLPApps\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris #아이리스 데이터는 ndarray형식으로 되어 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. data에는 각 꽃의 특성(feature)이 담겨있습니다.\n",
    "2. target은 data array와 짝이 일치합니다(어떤 식인지는 모르겠지만 이어져 있는 것 같습니다). 이는 각 행이 어떤 꽃을 나타내는지를 알려줍니다.\n",
    "– 0: Setosa, 1: Versicolor, 2: Virginica   <– target_names에 담겨있는 내용\n",
    "3. feature_names에는 data의 특성이 무엇을 의미하는지 알려준다.\n",
    "– [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’]    * sepal: 꽃받침 / petal: 꽃잎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iris.keys()) #load한 iris데이터의 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=iris.data #각 꽃의 특성에는 target data가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target값 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target명:  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#iris.target은 붓꽃 데이터 셋에서 레이블 데이터를 numpy로 가지고 있다. \n",
    "iris_label=iris.target\n",
    "print('iris target값 :',iris.target)  #어떤 품종인지를 알려주는 (얼마나 잘예측했는지를 보기 위한 척도)\n",
    "print('iris target명: ',iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#붓꽃 데이터 셋을 자세히 보기 위해 dataframe으로 변환한다\n",
    "iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target #새로운 변수를 label로 생성\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터로 학습된 모델이 얼마나 뛰어난 성능을 가지는지를 평가하려면 반드시 train,test로 나눠야 한다\n",
    "#random_state는 seed와 같은 역할을 한다고 본다\n",
    "X_train, X_test, y_train, y_test=train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier 객체의 생성\n",
    "dt_clf=DecisionTreeClassifier(random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습 수행(모델링을 시키는 작업)\n",
    "#어떻게 분류할지는 잡아주는 과정을 의미한다\n",
    "#학습용 feature data_set와 label_set을 객체에 지정하여 사용한다\n",
    "dt_clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 셋으로 예측을 시행\n",
    "#X_test_set이 학습된 모델을 얼마나 따르는지를 확인하려 fit해보는 과정\n",
    "pred=dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  0.9333\n"
     ]
    }
   ],
   "source": [
    "#정확성\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"예측 정확도: {0: .4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 셋 분리 : 데이터를 학습데이터와 테스트 데이터로 분리한다(모델링한 함수에 얼마나 fit되는지를 판단)\n",
    "- 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용하여 모델을 학습시킵니다\n",
    "- 예측 수행 : 학습된 ML모델을 이용하여 테스트 데이터의 분류를 예측한다\n",
    "- 평가 : 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교하여 정확성을 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. sklearn 기반 프레임워크 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn에서는 ML모델 학습을 위하여 fit()함수를,학습된 모델의 예측을 위하여 predict() 메서드를 제공합니다. sklearn의 두 분류로 classification과 regression이 있고, 이 둘을 합쳐 Estimator class라고 지칭합니다. 즉 지도학습의 모든 알고리즘을 구현한 클래스를 통칭하여 Estimator이라고 부릅니다. Estimator클래스는 fit()과 predict()를 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도 학습의 경우는 차원축소(PCA), 클러스터링, feature extraction등을 구현한 클래스가 있으며 이는 fit()과 transform()을 지원합니다. fit()은 입력 데이터의 형태에 맞춰 데이터를 변환시키기 위한 사전 구조를 맞추는 작업입니다. (즉 '어떻게 나눌지'를 결정하는 단계이다) \n",
    "fit()으로 변환을 위한 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처추출은 transform()으로 수행한다. sklearn은 fit()와 transform()을 합친 fit_transform()을 사용하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "예제 데이터 : sklearn.datasets  사이킷런에 내장된 예제 데이터 셋\n",
    "피처 처리 : sklearn.preprosessing  데이터 전처리(문자열을 숫자형으로 인코딩, 정규화, 스케일링)\n",
    "            sklearn.feature_selection  중요도 순으로 feature을 우선순위 나열\n",
    "            skelarn.feature_extraction  텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출\n",
    "피처처리 &차원축소 : sklearn.decomposing  차원축소와 관련한 알고리즘의 지원\n",
    "데이터분리, 검증 & 파라미터 튜닝 : sklearn.model_selection  교차검증을 위한 학습용/테스트용 분리, 최적의 parameter제공\n",
    "평가 : sklearn.metrics  평가방법 accuracy, precision, recall, roc-auc, rmse\n",
    "ml알고리즘 : sklearn.ensemble  앙상블 알고리즘 적용\n",
    "             sklearn.linear_model  회귀알고리즘 지원\n",
    "             sklearn.naive_bayes  나이브 베이즈 알고리즘 제공, k-NN등\n",
    "             sklearn.svm  서포트 벡터 머신 알고리즘\n",
    "             sklearn.tree  의사결정 트리 알고리즘\n",
    "             sklearn.cluster  비지도 클러스터링\n",
    "유틸리티  :  sklearn.pipline  피처처리 등의 변환과 ml알고리즘 학습 등을 묶어서 처리\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 내장된 예제 데이터 셋\n",
    "```\n",
    "-data는 피처의 데이터 세트를 의미한다\n",
    "-target은 분류시 레이블값, 회귀일 때는 숫자 결괏값 데이터로 나타낸다\n",
    "-target_names는 개별 레이블의 이름을 나타냅니다\n",
    "-feature_names는 피처의 이름을 나타냅니다\n",
    "-DESCR는 데이터 셋에 대한 설명과 각 피처의 설명을 나타냅니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data=load_iris()\n",
    "print(type(iris_data)) #예제 데이터의 타입 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 셋의 keys: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys=iris_data.keys()\n",
    "print(\"붓꽃 데이터 셋의 keys:\",keys) #내장된 데이터셋의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. model selcction 모듈의 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습/테스트 데이터 셋 분리-train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 셋을 이용하지 않고 학습 데이터만 학습하고 예측하면 무엇이 문제?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris() #데이터를 load하게 해주는 객체의 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clf=DecisionTreeClassifier() #객체 선언\n",
    "train_data=iris.data  \n",
    "train_label=iris.target\n",
    "dt_clf.fit(train_data, train_label) #학습 데이터로 모델을 생성(feature,y)를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "#학습 데이터로 예측\n",
    "pred=dt_clf.predict(train_data) #학습 데이터로 그대로 예측\n",
    "print(\"예측 정확도 : \",accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 반드시 train_test_split()을 사용해 주어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf=DecisionTreeClassifier() #트리모델 사용객체 선언\n",
    "iris_data=load_iris() #데이터 로드하는 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train) #모델을 학습(feature, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:0.9333\n"
     ]
    }
   ],
   "source": [
    "pred=dt_clf.predict(X_test)  #예측 (테스트 데이터로 예측을 위함)\n",
    "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))  #accuracy를 보기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 교차검증\n",
    "앞에서 시행한 방법은 ***Overfitting***에 취약하다. 모델이 학습 데이터에만 과도하게 최적화되어 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 것을 의미한다. 이런 문제점을 해결하고자 ***교차검증***을 이용하여 다양한 학습과 평가를 시행한다. 결국 교차검증은 데이터의 편중을 막기 위해 별도의 여러개의 셋으로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습된 평가를 수행하는 과정이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold 교차 검증\n",
    "먼저 k개의 데이터 폴드 셋을 만들어서 k번만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다. 5개의 폴드된 데이터 셋을 학습과 검증을 위한 데이터 셋트로 변경하면서 5번 평가를 수행한 뒤 이 ***5개의 평가를 평균한 결과***를 가지고 예측 성능을 평가하는 방법이다. <br> \n",
    "먼저 데이터 세트를 k(=5)등분합니다. 그리고 첫번째 반복에서는 1~4등분된 데이터를 학습 데이터 셋, 마지막 등분 데이터를 테스트 셋으로 평가를 수행합니다. <br> \n",
    "두번째 반복도 동일한 형태로 진행하되, 1~3+5번째 데이터를 학습 데이터로 사용하고 4번째 등분데이터를 테스트 데이터로 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<구현 클래스 소개>\n",
    "- KFold\n",
    "- Stratified K 폴드\n",
    "- GridSearchCV : 교차검증과 최적 hyperparameter 튜닝을 한번에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris() #데이터 로드 객체 생성\n",
    "features=iris.data\n",
    "label=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5개의 fold set으로 분리하는 Kfold 객체와 fold 셋별 정확도를 담을 수 있는 리스트 객체의 생성\n",
    "kfold=KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 셋의 크기: 150\n"
     ]
    }
   ],
   "source": [
    "cv_accuracy=[] #5개의 평가척도를 담을 리스트 객체의 생성\n",
    "print('붓꽃 데이터 셋의 크기:',features.shape[0]) #iris.data의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(kfold.split(features)) #(120, 30)개의 인덱스를 5fold로 나눠서 분류해준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1교차검증 정확도: 1.0, 학습 데이터의 크기: 120, 검증 데이터의 크기: 30\n",
      "\n",
      "#1검증세트 인덱스 :[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2교차검증 정확도: 0.9667, 학습 데이터의 크기: 120, 검증 데이터의 크기: 30\n",
      "\n",
      "#2검증세트 인덱스 :[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3교차검증 정확도: 0.8667, 학습 데이터의 크기: 120, 검증 데이터의 크기: 30\n",
      "\n",
      "#3검증세트 인덱스 :[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4교차검증 정확도: 0.9333, 학습 데이터의 크기: 120, 검증 데이터의 크기: 30\n",
      "\n",
      "#4검증세트 인덱스 :[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5교차검증 정확도: 0.7333, 학습 데이터의 크기: 120, 검증 데이터의 크기: 30\n",
      "\n",
      "#5검증세트 인덱스 :[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "#실제로 k-fold검증에서는 120, 30개로 나눠서 검증을 시행할 것이다(총 150) 이에 따라 split을 직접 수행하여야 한다\n",
    "n_iter=0 #몇번째 반복인지를 알려주기 위한 변수 \n",
    "\n",
    "#KFold객체의 split()를 호출하면 fold별 학습용, 검증용 테스트의 row인덱스를 array로 반환해준다. 이를 직접 나누면 된다\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test=features[train_index], features[test_index] #인덱스로 학습용 데이터 추출\n",
    "    y_train, y_test=label[train_index], label[test_index] #인덱스로 테스트용 데이터 추출\n",
    "    \n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train) #학습용 데이터로 모델 적합\n",
    "    pred=dt_clf.predict(X_test) #예측\n",
    "    n_iter+=1 #한번 반복이 돌아갔으므로 +1\n",
    "    \n",
    "    #반복시마다 정확도를 측정한다(평균을 구해야 하므로)\n",
    "    accuracy=np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print(\"\\n#{0}교차검증 정확도: {1}, 학습 데이터의 크기: {2}, 검증 데이터의 크기: {3}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"\\n#{0}검증세트 인덱스 :{1}\".format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 검증 정확도:  0.9\n"
     ]
    }
   ],
   "source": [
    "#개별 iteraion별 정확도를 합하여 평균 정확도 계산\n",
    "print(\"평균 검증 정확도: \",np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified K Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***불균형한 분포도***를 가진 레이블(결정 클래스) 데이터 집합을 위한 k fold방식입니다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 의미합니다. <br>\n",
    "Stratified K Fold는 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 제대로 반영하도록, 즉 '제대로 분배하도록'만드는 작업을 해준다. <br>\n",
    "***원본 데이터의 레이블 분포를 먼저 고려한 후에 이 분포와 동일하게*** 학습과 검증 데이터 셋을 분배한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris=load_iris() #필요한 예시 데이터 셋 로드\n",
    "iris_df=pd.DataFrame(data=iris.data, columns=iris.feature_names) #필요한 feature을 데이터프레임화\n",
    "iris_df['label']=iris.target #y값을 새로운 열로 할당\n",
    "iris_df['label'].value_counts() #극소한 양의 category도 count가 되는지를 판단하기 위한다(imbalance data를 다루므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StrafiedKFold는 KFold로 분할된 레이블 데이터 셋 전체가 레이블 값의 분포도를 반영하지 못하는 문제를 해결해 줍니다. KFold와의 큰 차이는 StratifiedKFold는 레이블 데이터 분포도에 따라 학습/검증 데이터를 나누기 때문에 split() 메서드 인자로 피처 데이터 셋뿐만 아니라 레이블 데이터 셋도 반드시 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차검증 : 1\n",
      "학습 레이블 데이터의 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터의 분포: \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 2\n",
      "학습 레이블 데이터의 분포 : \n",
      " 2    33\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터의 분포: \n",
      " 2    17\n",
      "1    17\n",
      "0    17\n",
      "Name: label, dtype: int64\n",
      "##교차검증 : 3\n",
      "학습 레이블 데이터의 분포 : \n",
      " 2    34\n",
      "1    34\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터의 분포: \n",
      " 2    16\n",
      "1    16\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf=StratifiedKFold(n_splits=3) #fold=3으로 하는 stratified적용\n",
    "n_iter=0\n",
    "\n",
    "#'분포'에 따라 인덱스가 지정되어야 하므로, 인덱스를 지정하는 skf.split()을 이용하여 데이터셋을 구성한다\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index] #위치기반 인덱싱으로 정해진 인덱스에 대한 데이터를 추출\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print(\"##교차검증 : {0}\".format(n_iter))\n",
    "    print(\"학습 레이블 데이터의 분포 : \\n\",label_train.value_counts())\n",
    "    print(\"검증 레이블 데이터의 분포: \\n\",label_test.value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 전체적인 데이터에서 각 카테고리별 분포를 고려하여 데이터 셋이 구성되었음을 인덱스를 통해 확인했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차 검증 정확도 : 0.9804,학습 데이터 크기:99, 검증 데이터 크기: 51\n",
      "\n",
      "2 교차 검증 정확도 : 0.9216,학습 데이터 크기:99, 검증 데이터 크기: 51\n",
      "\n",
      "3 교차 검증 정확도 : 0.9792,학습 데이터 크기:102, 검증 데이터 크기: 48\n"
     ]
    }
   ],
   "source": [
    "#즉 이를 바탕으로 데이터를 추출하여 모델fit, accuracy를 확인해본다\n",
    "dt_clf=DecisionTreeClassifier(random_state=156) #의사결정 트리 객체 생성\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[] #각 셋별로 정확도를 저장할 정확도 객체 생성\n",
    "\n",
    "#Stratified()의 경우, 전체 분포를 고려하므로 레이블 데이터 셋을 반드시 인자로 넣어야 한다\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "    #학습용, 검증용 데이터 추출\n",
    "    X_train, X_test=features[train_index], features[test_index]\n",
    "    y_train, y_test=label[train_index], label[test_index]\n",
    "    #학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    \n",
    "    #반복시마다 정확도를 측정\n",
    "    n_iter+=1\n",
    "    accuracy=np.round(accuracy_score(y_test, pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print(\"\\n{0} 교차 검증 정확도 : {1},학습 데이터 크기:{2}, 검증 데이터 크기: {3}\"\n",
    "         .format(n_iter, accuracy, train_size, test_size))\n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "교차 검증별 정확도 : [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도 :  0.9604\n"
     ]
    }
   ],
   "source": [
    "#각 교차 검증별 정확도 및 평균의 정확도 계산\n",
    "print(\"\\n교차 검증별 정확도 :\",np.round(cv_accuracy,4))\n",
    "print(\"평균 검증 정확도 : \",np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차검증을 보다 간편하게-cross_val_score() <br>\n",
    "앞의 StratifiedKFold 방법을 참고하면 **1.fold set을 설정하고 2.for loop로 학습 밑 테스트 데이터의 인덱스를 추출한 후에 3.반복적으로 학습하고 각 fold별 예측 성능을 반환**하는 작업을 수행했었다. cross_val_score()은 이런 일련의 과정을 한꺼번에 수행해주는 API이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 cross_val_score()은 classifier가 입력이 되면 Stratified KFold방식으로 레이블 값의 분포에 따라 학습/검증 데이터를 분할해 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=load_iris() #예제 데이터 로드 객체 선언\n",
    "dt_clf=DecisionTreeClassifier(random_state=156) #의사결정 트리 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iris_data.data #feature을 생성\n",
    "label=iris_data.target #y값(예측값)을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차검증별 정확도: [0.9804 0.9216 0.9792]\n",
      "평균 검증 정확도: 0.9604\n"
     ]
    }
   ],
   "source": [
    "#성능의 지표는 정확도, 교차검증의 세트는 3개이다\n",
    "#자동으로 검증별 정확도를 반환하게 해준다(for loop로 각각 인덱싱추출>적합할 필요가 없어진다)\n",
    "scores=cross_val_score(dt_clf,data, label, scoring='accuracy',cv=3) #(estimator, X,y,cv,scoring)을 인자로 받는다. \n",
    "print(\"교차검증별 정확도:\",np.round(scores,4))\n",
    "print(\"평균 검증 정확도:\",np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV - 교차검증과 최적하이퍼 파라미터 튜닝을 한번에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier이나 Regressor과 같은 알고리즘에 사용되는 hyper parameter을 순차적으로 입력하면서 편리하게 최적의 hyper parameter을 찾게 해 주는 방안을 제공하는 방법이다. 파라미터 집합을 만들고 이를 순차적으로 적용하면서 최적화를 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters={'max_depth':[1,2,3],\n",
    "                'min_samples_split':[2,3]} #총 6가지의 경우의 수를 모두 돌리게 하는 경우와 같이 순차적으로 계산이 될 예정이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- estimator : classifier, regressor, pipeline이 사용될 수 있다.\n",
    "- param_grid : key+list값을 가지는 dictionary가 주어딘다 \n",
    "- scoring : 예측 성능을 평가할 방법을 지정\n",
    "- cv : 교차검증을 위해 분할되는 학습/검증 데이터 세트의 개수를 지정한다\n",
    "- refit : 최적의 하이퍼파라미터를 찾은뒤 입력된 estimator을 해당 객체의 하이퍼파라미터에 적용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 로딩하고 학습 데이터, 테스트 데이터로 분리\n",
    "iris=load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier() #의사결정 나무 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter을 딕셔너리의 형태로 지정\n",
    "parameters={'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\NLPApps\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\.conda\\envs\\NLPApps\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\.conda\\envs\\NLPApps\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\.conda\\envs\\NLPApps\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\user\\.conda\\envs\\NLPApps\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#param_grid의 하이퍼 파라미어를 3개의 train, test set,fold로 나누어 테스트 수행 설정한다\n",
    "### reifit=True가 디폴트 값이며 가장 좋은 파라미터로 재학습 시킨다\n",
    "dtree=DecisionTreeClassifier() #의사결정 나무 객체 선언\n",
    "parameters={'max_depth':[1,2,3], 'min_samples_split':[2,3]} #순차적으로 대입할 하이퍼파라미터 객체 저장\n",
    "grid_dtree=GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "#붓꽃 학습 데이터로 param_grid의 하이터 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "#GridSearchCV 결과를 추출하여 DataFrame으로 전환한다\n",
    "scores_df=pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter의 경우의 수는 총 6가지이므로 총 6행의 값이 출력되어 있다. 이에 대해 split0_test_score, split1_test_score, split2_test_score은 총 3개의 폴드 각각에 대한 정확도 값을 의미하고 mean은 이 3가지의 평균 값, rank는 이 정확도의 mean에 대해 순위를 매긴 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적의 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV객체에 fit()을 수행하면 최고 성능 하이퍼 파라미터를 적용한 모델\n",
    "print('GridSearchCV 최적의 파라미터 :',grid_dtree.best_params_) #최적의 파라미터 조합을 선정\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
